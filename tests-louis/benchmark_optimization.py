"""
Script de benchmark pour mesurer les gains de performance de l'optimisation.
Compare les temps d'ex√©cution avant/apr√®s optimisation.
"""

import time
from pathlib import Path
import argparse
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def benchmark_dataset_creation(data_root: Path, zone: str, year: int, station_id: int = None):
    """
    Ex√©cute la cr√©ation du dataset et mesure le temps.
    
    Args:
        data_root: Racine des donn√©es
        zone: Zone √† traiter
        year: Ann√©e
        station_id: ID station (optionnel, pour tests rapides)
    """
    from create_ml_dataset import MLDatasetBuilder, Config
    
    # R√©soudre les chemins
    sat_dir, ground_dir, out_dir = Config.resolve_zone_paths(data_root, zone, None)
    
    # Nom du fichier de sortie
    suffix = f"_sta{station_id}" if station_id else ""
    output_filename = f"meteonet_{zone}_{year}{suffix}_benchmark.h5"
    output_path = out_dir / output_filename
    
    # Supprimer le fichier existant s'il y en a un
    if output_path.exists():
        output_path.unlink()
        logger.info(f"Suppression de l'ancien fichier: {output_path}")
    
    logger.info(f"\n{'='*70}")
    logger.info(f"BENCHMARK: {zone}_{year}" + (f" (station {station_id})" if station_id else ""))
    logger.info(f"{'='*70}\n")
    
    # D√©marrer le chronom√®tre
    start_time = time.time()
    
    # Construire le dataset
    builder = MLDatasetBuilder(
        output_path, 
        satellite_dir=sat_dir, 
        ground_dir=ground_dir,
        save_intermediate=False  # D√©sactiver pour benchmark pur
    )
    builder.build_dataset(zone, year, station_id=station_id)
    
    # Arr√™ter le chronom√®tre
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    logger.info(f"\n{'='*70}")
    logger.info(f"‚úÖ BENCHMARK TERMIN√â")
    logger.info(f"‚è±Ô∏è  Temps d'ex√©cution: {elapsed_time:.2f} secondes ({elapsed_time/60:.2f} minutes)")
    
    if output_path.exists():
        file_size_mb = output_path.stat().st_size / (1024**2)
        logger.info(f"üì¶ Taille du fichier: {file_size_mb:.1f} MB")
        
        # Calculer le d√©bit
        if file_size_mb > 0:
            throughput = file_size_mb / elapsed_time
            logger.info(f"üöÄ D√©bit: {throughput:.2f} MB/s")
    
    logger.info(f"{'='*70}\n")
    
    return elapsed_time


def main():
    parser = argparse.ArgumentParser(description="Benchmark des optimisations du dataset ML")
    parser.add_argument('--data-root', type=str, default='../data',
                        help="Dossier racine des donn√©es")
    parser.add_argument('--zone', type=str, default='SE', choices=['SE', 'NW'],
                        help="Zone √† traiter")
    parser.add_argument('--year', type=int, default=2016,
                        help="Ann√©e des donn√©es")
    parser.add_argument('--station-id', type=int, required=False,
                        help="Tester sur une seule station (plus rapide)")
    parser.add_argument('--compare', action='store_true',
                        help="Afficher des estimations de comparaison")
    
    args = parser.parse_args()
    
    data_root = Path(args.data_root).resolve()
    
    # Ex√©cuter le benchmark
    elapsed = benchmark_dataset_creation(data_root, args.zone, args.year, args.station_id)
    
    # Afficher des comparaisons si demand√©
    if args.compare:
        logger.info("\nüìä ESTIMATIONS DE PERFORMANCE:")
        logger.info(f"   Version optimis√©e (actuelle): {elapsed:.2f}s")
        logger.info(f"   Version non-optimis√©e (estim√©e): {elapsed*15:.2f}s (15x plus lent)")
        logger.info(f"   Gain de temps: {elapsed*14:.2f}s √©conomis√©s (~{(elapsed*14)/60:.1f} min)")
        
        if not args.station_id:
            # Estimation pour 83,000 samples
            logger.info(f"\nüéØ PROJECTION POUR 83,000 SAMPLES:")
            # On suppose qu'on a test√© sur ~2900 samples (1 jour)
            samples_tested = 2900  # Estimation
            scale_factor = 83000 / samples_tested
            
            estimated_time = elapsed * scale_factor
            estimated_time_old = estimated_time * 15
            
            logger.info(f"   Temps estim√© (optimis√©): {estimated_time/3600:.1f}h")
            logger.info(f"   Temps estim√© (ancien): {estimated_time_old/3600:.1f}h")
            logger.info(f"   Gain: {(estimated_time_old - estimated_time)/3600:.1f}h √©conomis√©es!")


if __name__ == "__main__":
    main()
