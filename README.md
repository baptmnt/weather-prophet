
# Weather Prophet ğŸŒ¦ï¸

Projet de prÃ©diction mÃ©tÃ©orologique par Machine Learning Ã  partir de donnÃ©es satellites et de stations au sol.

## ğŸ¯ Objectif du projet

CrÃ©er un modÃ¨le de ML capable de **prÃ©dire les conditions mÃ©tÃ©orologiques au sol** (tempÃ©rature, humiditÃ©, prÃ©cipitations, etc.) Ã  partir d'**images satellites historiques**.

### Principe

```text
Images satellites passÃ©es â†’ ModÃ¨le ML â†’ PrÃ©diction mÃ©tÃ©o au sol
(t-12h, t-1j, t-2j, t-7j)              (tempÃ©rature, humiditÃ©, etc.)
```

---

## ğŸ“ Structure du projet

```text
weather-prophet/
â”œâ”€â”€ README.md                  # ğŸ“– Ce fichier - documentation principale
â”œâ”€â”€ tests-louis/               # ğŸ§ª Scripts de traitement et ML
â”‚   â”œâ”€â”€ create_ml_dataset.py       # ğŸ”§ GÃ©nÃ¨re le dataset HDF5 d'entraÃ®nement
â”‚   â”œâ”€â”€ inspect_dataset.py         # ğŸ” Inspecte et visualise le dataset
â”‚   â”œâ”€â”€ pytorch_dataloader.py      # ğŸš€ DataLoader PyTorch pour le ML
â”‚   â”œâ”€â”€ test_dataloader.py         # âœ… Test rapide du DataLoader
â”‚   â””â”€â”€ README_DATASET.md          # ğŸ“– Documentation dÃ©taillÃ©e du dataset
â”œâ”€â”€ datasets/                  # ğŸ“Š Datasets HDF5 gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ meteonet_SE_2016_20160101.h5
â”‚   â””â”€â”€ *.png                  # Visualisations de samples
â””â”€â”€ data_extraction/           # Scripts d'extraction (legacy)
```

---

## ğŸš€ Guide d'utilisation rapide

### PrÃ©requis

```bash
# Installation des dÃ©pendances
pip install xarray h5netcdf h5py numpy pandas matplotlib torch torchvision imageio pillow
```

### 1ï¸âƒ£ GÃ©nÃ©rer le dataset ML

Le script `tests-louis/create_ml_dataset.py` combine les donnÃ©es satellites (.nc) et stations au sol (CSV) en un seul fichier HDF5 optimisÃ©.

**âœ¨ Optimisations v2.1 (PrÃ©-indexation + Vectorisation)** :

- ğŸš€ **Ã‰tape 1 - PrÃ©-indexation temporelle** : 8-71x plus rapide grÃ¢ce Ã  la recherche dichotomique O(log n)
- âš¡ **Ã‰tape 2 - Vectorisation par timestamp** : 14.6x plus rapide en groupant les requÃªtes
- ğŸ¯ **Gain cumulÃ©** : 117-1036x plus rapide que la version initiale
- ğŸ“Š RÃ©duction de 95% des chargements d'images redondants
- ğŸ’¾ Cache intelligent multi-niveaux pour rÃ©utilisation maximale

```bash
cd tests-louis

# Utilisation de base (avec chemins relatifs configurables)
python create_ml_dataset.py --data-root ../data --zone SE --year 2016

# Avec options avancÃ©es
python create_ml_dataset.py \
    --data-root ../data \
    --zone SE \
    --year 2016 \
    --output-dir ./datasets \
    --station-id 7149 \
    --save-intermediate \
    --chunk-size 500
```

**Arguments disponibles** :

- `--data-root` : Dossier racine contenant les zones (dÃ©faut : `data/`)
- `--zone` : Zone Ã  traiter (`SE` ou `NW`, dÃ©faut : `SE`)
- `--year` : AnnÃ©e des fichiers satellites (dÃ©faut : `2016`)
- `--output-dir` : Dossier de sortie (dÃ©faut : `data/<ZONE>/datasets/`)
- `--station-id` : Filtrer sur une station spÃ©cifique (optionnel)
- `--save-intermediate` : Sauvegarder des chunks intermÃ©diaires .npz
- `--chunk-size` : Taille des chunks (dÃ©faut : 500 samples)
- `--build-final` : Merger des chunks existants sans reconstruire
- `--merge-start` / `--merge-end` : SÃ©lectionner la plage de chunks Ã  merger
- `--intermediate-dir` : Dossier pour fichiers temporaires

**Configuration** (Ã  modifier dans le script si nÃ©cessaire) :

```python
zone = 'SE'  # ou 'NW' (South-East ou North-West France)
year = 2016
```

**Optimisations de performance intÃ©grÃ©es** :

1. **PrÃ©-indexation temporelle** : Les timestamps sont indexÃ©s au chargement â†’ recherche O(log n) au lieu de O(n)
2. **Recherche dichotomique** : Utilisation de `bisect` pour trouver les timestamps les plus proches
3. **Vectorisation par timestamp** : Groupement des stations par timestamp pour charger les images une seule fois
4. **Cache multi-niveaux** : Les images et ensembles multi-temporels sont mis en cache pour rÃ©utilisation maximale
5. **RÃ©duction I/O** : 95% moins de lectures disque grÃ¢ce au partage d'images entre stations

**Sortie** :

- `datasets/meteonet_SE_2016.h5` (~740 MB par jour)
- Logs de progression et statistiques de construction

**Ce que fait le script** :

1. âœ… Charge les fichiers satellites NetCDF (CT, IR039, IR108, VIS06, WV062) avec **indexation temporelle**
2. âœ… Charge les mesures des stations au sol depuis le CSV avec **prÃ©-indexation (station, timestamp)**
3. âœ… **Groupement intelligent** : Traite les stations par batch de timestamps identiques
4. âœ… Pour chaque timestamp unique :
    - Extrait les **images satellites complÃ¨tes** Ã  t-12h, t-24h, t-48h, t-168h **une seule fois** via **recherche dichotomique O(log n)**
    - RÃ©utilise ces images pour **toutes les stations** du mÃªme timestamp
    - RÃ©cupÃ¨re les mesures au sol (t, hu, precip, dd, ff, psl, td) pour chaque station
    - Aligne temporellement et spatialement les donnÃ©es
5. âœ… Sauvegarde en format HDF5 compressÃ© avec metadata (ou chunks intermÃ©diaires .npz)

**Temps d'exÃ©cution** :

- âš¡ **v2.1 optimisÃ©** : ~0.5-2 secondes pour 1 jour de donnÃ©es (117-1036x plus rapide)
- ğŸ“¦ **Mode chunks** : Traite par blocs de 500 samples pour Ã©viter la saturation mÃ©moire
- ğŸ¯ **83,000 samples** : EstimÃ© Ã  ~12-30 secondes au lieu de plusieurs heures

---

### 2ï¸âƒ£ Inspecter le dataset

Le script `tests-louis/inspect_dataset.py` permet de vÃ©rifier la qualitÃ© et la structure du dataset gÃ©nÃ©rÃ©.

```bash
cd tests-louis
python inspect_dataset.py [chemin_dataset.h5]
```

Si aucun chemin n'est fourni, il inspecte automatiquement le dernier dataset crÃ©Ã©.

**Ce qu'il affiche** :

- ğŸ“‹ Structure du fichier HDF5 (dimensions, attributs)
- ğŸ“Š Statistiques sur les images et labels (min, max, mean, NaN%)
- ğŸ“ Info spatiales (stations, coordonnÃ©es)
- â° Info temporelles (pÃ©riode couverte)
- ğŸ” QualitÃ© des donnÃ©es (complÃ©tude par canal et timestep)
- ğŸ¨ Visualisations de samples alÃ©atoires (PNG gÃ©nÃ©rÃ©s)

**Sortie** :

- Statistiques dans le terminal
- `datasets/sample_XXX_visualization.png` (3 samples alÃ©atoires)

---

### 3ï¸âƒ£ Charger le dataset avec PyTorch

Le script `tests-louis/pytorch_dataloader.py` fournit un DataLoader prÃªt Ã  l'emploi pour l'entraÃ®nement.

#### Utilisation simple

```python
from tests-louis.pytorch_dataloader import create_dataloaders
from pathlib import Path

# CrÃ©er les DataLoaders (train/val/test splits automatiques)
train_loader, val_loader, test_loader = create_dataloaders(
    Path("datasets/meteonet_SE_2016_20160101.h5"),
    batch_size=32,
    train_split=0.7,    # 70% train
    val_split=0.15,     # 15% validation
    num_workers=4       # Chargement parallÃ¨le
)

# ItÃ©rer sur les batchs
for images, labels, metadata in train_loader:
    # images: (batch_size, 4_timesteps, 5_channels, height, width)
    # labels: (batch_size, 7_variables)
    # metadata: dict avec timestamp, station_id, coords, etc.

    # â†’ Votre modÃ¨le ici !
    predictions = model(images)
    loss = criterion(predictions, labels)
    # ...
```

#### Utilisation avancÃ©e

```python
from tests-louis.pytorch_dataloader import MeteoNetDataset

# Dataset custom avec options
dataset = MeteoNetDataset(
    h5_path,
    normalize=True,        # Normalisation Z-score par canal
    handle_nans='zero',    # Options: 'zero', 'mean', 'keep'
    transform=None,        # Transformations custom (augmentation)
)

# AccÃ©der aux infos du dataset
print(dataset.get_channel_names())  # ['CT', 'IR039', 'IR108', 'VIS06', 'WV062']
print(dataset.get_target_names())   # ['dd', 'ff', 'precip', 'hu', 'td', 't', 'psl']
print(dataset.get_timesteps())      # [-12, -24, -48, -168]
```

---

### 4ï¸âƒ£ Tester le DataLoader

Script de test rapide pour vÃ©rifier que tout fonctionne.

```bash
cd tests-louis
python test_dataloader.py
```

**Ce qu'il fait** :

- âœ… Charge le dataset
- âœ… CrÃ©e les DataLoaders
- âœ… Teste le chargement d'un batch
- âœ… Affiche les shapes et statistiques

**Sortie attendue** :

```text
âœ… TOUT FONCTIONNE PARFAITEMENT!

ğŸš€ Vous pouvez maintenant:
    1. CrÃ©er un modÃ¨le PyTorch
    2. ItÃ©rer sur train_loader pour l'entraÃ®nement
    3. Ã‰valuer sur val_loader et test_loader
```

---

## ğŸ“Š Format du dataset

### Structure HDF5

```text
dataset.h5
â”œâ”€â”€ images/                    (N, 4, 5, 171, 261)
â”‚   â””â”€â”€ Images satellites :
â”‚       - Dimension 0: Samples
â”‚       - Dimension 1: Timesteps [-12h, -24h, -48h, -168h]
â”‚       - Dimension 2: Canaux [CT, IR039, IR108, VIS06, WV062]
â”‚       - Dimension 3-4: Spatial (171Ã—261 pixels, ~3km/pixel)
â”‚
â”œâ”€â”€ labels/                    (N, 7)
â”‚   â””â”€â”€ Variables mÃ©tÃ©o au sol :
â”‚       [dd, ff, precip, hu, td, t, psl]
â”‚
â””â”€â”€ metadata/
    â”œâ”€â”€ timestamps         Timestamp de chaque sample
    â”œâ”€â”€ station_ids        ID de la station
    â”œâ”€â”€ station_coords     CoordonnÃ©es (lat, lon)
    â”œâ”€â”€ station_heights    Altitude (m)
    â””â”€â”€ zones             Zone gÃ©ographique ('NW' ou 'SE')
```

### Variables

**Canaux satellites** :

- `CT` : Type de nuage (0-15, catÃ©goriel)
- `IR039` : Infrarouge 3.9 Âµm (Â°C)
- `IR108` : Infrarouge 10.8 Âµm (Â°C)
- `VIS06` : Visible 0.6 Âµm (%, jour uniquement)
- `WV062` : Vapeur d'eau 6.2 Âµm (Â°C)

**Labels stations** :

- `dd` : Direction du vent (Â°)
- `ff` : Vitesse du vent (m.s^-1^)
- `precip` : PrÃ©cipitations (kg.m^2^)
- `hu` : HumiditÃ© (%)
- `td` : TempÃ©rature du point de rosÃ©e (K)
- `t` : TempÃ©rature (K)
- `psl` : Pression au niveau de la mer (Pa)

---

## ğŸ”§ Configuration et personnalisation

### Modifier les timesteps

Dans `tests-louis/create_ml_dataset.py` :

```python
class Config:
    TIMESTEPS = [-6, -12, -24, -72]  # 6h, 12h, 1j, 3j au lieu de [-12, -24, -48, -168]
```

### Changer les canaux satellites

```python
class Config:
    CHANNELS = ['IR108', 'VIS06', 'WV062']  # Seulement 3 canaux
```

### SÃ©lectionner certaines variables cibles

```python
class Config:
    TARGET_VARS = ['t', 'hu', 'precip']  # Seulement tempÃ©rature, humiditÃ©, prÃ©cipitations
```

### Ajuster la normalisation

```python
dataset = MeteoNetDataset(
    h5_path,
    normalize=True,      # True = normalisation Z-score
    handle_nans='zero'   # 'zero' | 'mean' | 'keep'
)
```

---

## ğŸ“ˆ Statistiques du dataset (exemple SE_20160101)

### DonnÃ©es gÃ©nÃ©rales

- **Samples** : 2902
- **Stations uniques** : 335
- **Dimensions images** : 171 Ã— 261 pixels
- **Canaux disponibles** : 4 (IR039, IR108, VIS06, WV062) - CT absent pour SE
- **Taux de rÃ©ussite** : 60% (samples avec images ET labels valides)

### QualitÃ© des labels

| Variable | Couverture | Min     | Max      | Mean    |
|----------|-----------|---------|----------|---------|
| t        | 99.9%     | 264 K   | 288 K    | 281 K   |
| hu       | 97.9%     | 44%     | 106%     | 88%     |
| precip   | 96.9%     | 0 kg/mÂ² | 0.8 kg/mÂ²| 0.02    |
| dd       | 93.5%     | 0Â°      | 360Â°     | 138Â°    |
| ff       | 93.5%     | 0 m/s   | 13.7 m/s | 3.4 m/s |
| td       | 97.6%     | 263 K   | 286 K    | 279 K   |
| psl      | 20.0%     | 101190 Pa | 102270 Pa | 101785 Pa |

**Note** : `psl` a peu de couverture (beaucoup de stations ne mesurent pas cette variable).

---

## ğŸ§  Architecture recommandÃ©e pour le ML

### Pourquoi des images complÃ¨tes ?

âœ… **Contexte spatial** : Le modÃ¨le voit les systÃ¨mes mÃ©tÃ©o qui s'approchent  
âœ… **Dynamique temporelle** : Apprend la vitesse/direction des mouvements  
âœ… **GÃ©nÃ©ralisation** : Comprend la relation "mÃ©tÃ©o rÃ©gionale â†’ mÃ©tÃ©o locale"  
âœ… **EfficacitÃ©** : Une image sert pour toutes les stations de la zone

### Timesteps choisis

- **t-12h** : Tendance court terme
- **t-24h** : Ã‰volution sur 1 jour
- **t-48h** : Dynamique Ã  2 jours
- **t-168h** : Contexte hebdomadaire

### Suggestions d'architectures

1. **CNN 3D** : Pour traiter sÃ©quences spatiotemporelles
2. **ConvLSTM** : Combine convolutions + mÃ©moire temporelle
3. **U-Net temporel** : Si vous voulez faire de la prÃ©diction spatiale complÃ¨te
4. **Vision Transformer** : Pour capturer dÃ©pendances long-terme

---

## ğŸ“š Documentation complÃ¨te

Pour plus de dÃ©tails sur la structure HDF5, l'utilisation avancÃ©e, le troubleshooting, etc. :

ğŸ‘‰ **Voir `tests-louis/README_DATASET.md`**

---

## âš ï¸ Points d'attention

### Valeurs manquantes (NaN)

- **VIS06** : Pas de donnÃ©es la nuit (normal)
- **CT** : Peut Ãªtre absent selon la zone
- **Labels** : `psl` souvent absent (80% de NaN)

**Recommandation** : Utiliser `handle_nans='zero'` dans le DataLoader.

### Performance

- **Dataset complet** : ~740 MB pour 1 jour â†’ ~270 GB pour 1 an
- **Solution** : HDF5 permet le chargement lazy (pas tout en RAM)
- **Optimisation** : Augmenter `num_workers` dans le DataLoader

### Gestion mÃ©moire

```python
# Pour gros datasets, rÃ©duire batch_size ou utiliser gradient accumulation
train_loader = DataLoader(dataset, batch_size=16)  # Au lieu de 32
```

---

## ğŸš€ Prochaines Ã©tapes

### Pour commencer l'entraÃ®nement

1. **CrÃ©er un modÃ¨le simple** pour tester le pipeline
2. **DÃ©finir la loss function** (MSE, MAE, ou custom ignorant les NaN)
3. **EntraÃ®ner** sur quelques epochs
4. **Ã‰valuer** les performances sur val/test

### Pour Ã©tendre le dataset

1. **Dataset complet** : GÃ©nÃ©rer pour toute l'annÃ©e 2016
2. **Multi-zones** : Combiner NW et SE
3. **Autres sources** : Ajouter donnÃ©es radar, AROME/ARPEGE
4. **Multi-annÃ©es** : 2016, 2017, 2018...

---

## ğŸ› Troubleshooting

### Erreur "No module named 'h5py'"

```bash
pip install h5py
```

### Erreur "Indexing elements must be in increasing order"

HDF5 nÃ©cessite des indices triÃ©s :

```python
indices = np.sort(indices)
```

### Performances lentes

- Augmenter `num_workers` dans DataLoader
- VÃ©rifier que le HDF5 est sur un SSD
- RÃ©duire `batch_size` si RAM insuffisante

### Dataset trop gros

- RÃ©duire la pÃ©riode (1 semaine au lieu de 1 mois)
- Sous-Ã©chantillonner temporellement (1 sample toutes les 3h)
- Utiliser moins de canaux satellites

---

## ğŸ“ Contact et contribution

Projet dÃ©veloppÃ© dans le cadre du TIP - INSA Lyon 4TCA.

**Sources de donnÃ©es** : [MeteoNet](https://meteonet.umr-cnrm.fr/) - MÃ©tÃ©o-France

---

## ğŸ“„ Licence

Voir `LICENCE.md` pour les dÃ©tails.

---

Bon entraÃ®nement ! ğŸŒ¦ï¸ğŸš€
