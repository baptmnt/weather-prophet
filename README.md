
# Weather Prophet ğŸŒ¦ï¸

Projet de prÃ©diction mÃ©tÃ©orologique par Machine Learning Ã  partir de donnÃ©es satellites et de stations au sol.

## ğŸ¯ Objectif du projet

CrÃ©er un modÃ¨le de ML capable de **prÃ©dire les conditions mÃ©tÃ©orologiques au sol** (tempÃ©rature, humiditÃ©, prÃ©cipitations, etc.) Ã  partir d'**images satellites historiques**.

### Principe

```text
Images satellites passÃ©es â†’ ModÃ¨le ML â†’ PrÃ©diction mÃ©tÃ©o au sol
(t-12h, t-1j, t-2j, t-7j)              (tempÃ©rature, humiditÃ©, etc.)
```

---

## ğŸ“ Structure du projet

```text
weather-prophet/
â”œâ”€â”€ README.md                  # ğŸ“– Ce fichier - documentation principale
â”œâ”€â”€ tests-louis/               # ğŸ§ª Scripts de traitement et ML
â”‚   â”œâ”€â”€ create_ml_dataset.py       # ğŸ”§ GÃ©nÃ¨re le dataset HDF5 d'entraÃ®nement
â”‚   â”œâ”€â”€ inspect_dataset.py         # ğŸ” Inspecte et visualise le dataset
â”‚   â”œâ”€â”€ pytorch_dataloader.py      # ğŸš€ DataLoader PyTorch pour le ML
â”‚   â”œâ”€â”€ test_dataloader.py         # âœ… Test rapide du DataLoader
â”‚   â””â”€â”€ README_DATASET.md          # ğŸ“– Documentation dÃ©taillÃ©e du dataset
â”œâ”€â”€ datasets/                  # ğŸ“Š Datasets HDF5 gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ meteonet_SE_2016_20160101.h5
â”‚   â””â”€â”€ *.png                  # Visualisations de samples
â””â”€â”€ data_extraction/           # Scripts d'extraction (legacy)
```

---

## ğŸš€ Guide d'utilisation rapide

### PrÃ©requis

```bash
# Installation des dÃ©pendances
pip install xarray h5netcdf h5py numpy pandas matplotlib torch torchvision imageio pillow
```

### 1ï¸âƒ£ GÃ©nÃ©rer le dataset ML

Le script `tests-louis/create_ml_dataset.py` combine les donnÃ©es satellites (.nc) et stations au sol (CSV) en un seul fichier HDF5 optimisÃ©.

#### ğŸ¯ Filtrer uniquement la station de Bron (ID 69029001)

Pour ce projet, nous nous concentrons uniquement sur la station de Bron, prÃ¨s de Lyon (ID MeteoNet: 69029001).

- Windows PowerShell (depuis la racine du repo):

```powershell
python "weather-prophet\tests-louis\create_ml_dataset.py" --zone SE --year 2016 --data-root ".\meteonet\data_samples" --num-workers 1 --station-id 69029001
```

- Linux/macOS:

```bash
python weather-prophet/tests-louis/create_ml_dataset.py --zone SE --year 2016 --data-root ./meteonet/data_samples --num-workers 1 --station-id 69029001
```

Sortie attendue:

- Fichier: `meteonet_SE_2016_sta69029001.h5`
- Taille: ~1.7 MB
- Temps dâ€™exÃ©cution: ~9 s (chargement + indexation + Ã©criture gzip)

#### âš ï¸ Activation du venv (Important !)

**Sur Windows PowerShell** :

```powershell
# Se placer Ã  la racine du projet
cd "d:\Documents\ScolaritÃ©\5 - INSA Lyon\4TCA\S3\TIP\Projet"

# Activer le venv
& .\.venv\Scripts\Activate.ps1

# Maintenant vous pouvez utiliser les scripts
cd weather-prophet\tests-louis
python create_ml_dataset.py --help
```

**Sur Linux/macOS** :

```bash
# Se placer Ã  la racine du projet
cd /path/to/projet

# Activer le venv
source .venv/bin/activate

# Maintenant vous pouvez utiliser les scripts
cd weather-prophet/tests-louis
python create_ml_dataset.py --help
```

ğŸ’¡ **Astuce** : Une fois le venv activÃ©, vous verrez `(.venv)` au dÃ©but de votre prompt.

#### âœ¨ Optimisations v2.2 â€” rÃ©capitulatif synthÃ©tique

- ğŸš€ PrÃ©-indexation temporelle (bisect O(log n)) â€” Gain mesurÃ©: 8â€“71Ã—
- âš¡ Vectorisation par timestamp (groupby des datetime) â€” Gain: 14.6Ã—, ~95% dâ€™I/O disque en moins
- ğŸ§  Cache multi-niveaux (images uniques + multi-temporel)
- ğŸ§µ ParallÃ©lisation multi-processus par chunks de timestamps
  - ProblÃ¨me initial: un seul CPU utilisÃ©
  - Solution: dÃ©couper en batches de timestamps pour parallÃ©liser le travail
  - Gain: utilise tous les cÅ“urs disponibles â†’ ~4â€“8Ã— selon le nombre de cÅ“urs (Linux/macOS)
  - Note: sur Windows, lâ€™overhead de spawn peut annuler le gain; le mode sÃ©quentiel reste recommandÃ©
- ğŸ’¾ Ã‰criture HDF5 directe (fin des .npz intermÃ©diaires lents)
  - Suppression de `np.savez_compressed` et des merges intermÃ©diaires
  - Nouveau flux: comptage des samples valides â†’ prÃ©-allocation exacte â†’ remplissage direct â†’ Ã©criture HDF5
  - RÃ©sultat mesurÃ© (SE 2016, 4767 samples): ~2 min 40 s avec gzip (fichier ~92 MB)
  - Station unique (Bron, 10 samples): ~9 s (fichier ~1.7 MB)
- ğŸ§® MÃ©moire optimisÃ©e: prÃ©-allocation EXACTE (deux passes)
  - Ã‰vite lâ€™allocation catastrophique (ex: 371 GiB) en allouant uniquement le nombre de samples valides

RÃ©sumÃ© rapide des gains rÃ©cents:

- 14 min â†’ ~2 min 40 s pour 4767 samples (gzip activÃ©)
- Single station (Bron) en ~9 s

```bash
cd tests-louis

# Utilisation de base (avec chemins relatifs configurables)
python create_ml_dataset.py --data-root ../data --zone SE --year 2016

# Avec options avancÃ©es
python create_ml_dataset.py \
    --data-root ../data \
    --zone SE \
    --year 2016 \
    --output-dir ./datasets
```

â„¹ï¸ Remarque: la gÃ©nÃ©ration sâ€™effectue dÃ©sormais en **un seul passage** avec **Ã©criture HDF5 directe** (compression gzip). Les fichiers `.npz` intermÃ©diaires ont Ã©tÃ© retirÃ©s car trop lents; lâ€™option `--save-intermediate` nâ€™est plus nÃ©cessaire dans le flux par dÃ©faut.

**Arguments disponibles** :

- `--data-root` : Dossier racine contenant les zones (dÃ©faut : `data/`)
- `--zone` : Zone Ã  traiter (`SE` ou `NW`, dÃ©faut : `SE`)
- `--year` : AnnÃ©e des fichiers satellites (dÃ©faut : `2016`)
- `--output-dir` : Dossier de sortie (dÃ©faut : `data/<ZONE>/datasets/`)
- `--station-id` : Filtrer sur une station spÃ©cifique (optionnel)
- `--save-intermediate` : (option legacy) Ã©crit des chunks `.npz` temporaires puis merge; non recommandÃ© sauf besoin spÃ©cifique
- `--chunk-size` : Taille des chunks (dÃ©faut : 500 samples)
- `--num-workers` : Nombre de processus parallÃ¨les (voir section ParallÃ©lisation ci-dessous)
- `--build-final` : Merger des chunks existants sans reconstruire
- `--merge-start` / `--merge-end` : SÃ©lectionner la plage de chunks Ã  merger
- `--intermediate-dir` : Dossier pour fichiers temporaires

ğŸ’¡ **Astuce** : Pour traiter de gros datasets (plusieurs jours/mois), utilisez **toujours** `--save-intermediate` pour Ã©viter de saturer la RAM et accÃ©lÃ©rer l'Ã©criture finale.

#### âš¡ ParallÃ©lisation (optionnel)

Le script supporte le traitement parallÃ¨le via l'argument `--num-workers` :

```bash
# Mode sÃ©quentiel (dÃ©faut, recommandÃ©)
python create_ml_dataset.py --num-workers 1

# Mode parallÃ¨le (4 workers)
python create_ml_dataset.py --num-workers 4

# Auto (utilise tous les CPUs disponibles)
python create_ml_dataset.py --num-workers 0

# Sans argument : question interactive au lancement
python create_ml_dataset.py
```

**Configuration interactive** :

Si vous n'utilisez pas `--num-workers`, le script vous posera la question au dÃ©marrage :

```text
======================================================================
âš™ï¸  CONFIGURATION DE LA PARALLÃ‰LISATION
======================================================================

Votre machine dispose de 8 CPU(s).

Options de parallÃ©lisation:
  â€¢ 1 worker  : Mode sÃ©quentiel (recommandÃ© pour Windows, stable)
  â€¢ 2-4 workers : ParallÃ©lisation modÃ©rÃ©e (peut ralentir sur Windows)
  â€¢ 0 (auto)  : Tous les CPUs disponibles

âš ï¸  Note: Sur Windows, la parallÃ©lisation ajoute un overhead significatif
   et peut Ãªtre PLUS LENTE que le mode sÃ©quentiel. Le mode sÃ©quentiel
   est dÃ©jÃ  trÃ¨s rapide grÃ¢ce aux optimisations (prÃ©-indexation + vectorisation).

Nombre de workers Ã  utiliser [dÃ©faut: 1] : _
```

**âš ï¸ Important - ParallÃ©lisation sur Windows** :

- âŒ **Sur Windows**, la parallÃ©lisation peut Ãªtre **PLUS LENTE** qu'en mode sÃ©quentiel
- ğŸŒ **Overhead significatif** : Windows utilise `spawn` au lieu de `fork` â†’ chaque processus doit rÃ©importer tous les modules
- âœ… **Mode sÃ©quentiel recommandÃ©** : Les optimisations de prÃ©-indexation + vectorisation rendent le mode sÃ©quentiel dÃ©jÃ  trÃ¨s rapide (117-1036x)
- ğŸš€ **Sur Linux/macOS** : La parallÃ©lisation peut apporter un gain de 2-4x supplÃ©mentaire

**RÃ©sultats de benchmarks (Windows)** :

| Workers | Temps (1000 items) | EfficacitÃ© | Recommandation |
|---------|-------------------|------------|----------------|
| 1       | 1.00s            | 100%       | âœ… **RecommandÃ©** |
| 2       | 1.15s            | 44%        | âš ï¸ Plus lent |
| 4       | 1.10s            | 23%        | âš ï¸ Plus lent |
| 8       | 1.52s            | 8%         | âŒ Bien plus lent |

ğŸ’¡ **Conclusion** : Utilisez `--num-workers 1` (ou laissez la valeur par dÃ©faut) pour des performances optimales sur Windows.

**Configuration** (Ã  modifier dans le script si nÃ©cessaire) :

```python
zone = 'SE'  # ou 'NW' (South-East ou North-West France)
year = 2016
```

**Optimisations de performance intÃ©grÃ©es** :

1. **PrÃ©-indexation temporelle** : Les timestamps sont indexÃ©s au chargement â†’ recherche O(log n) au lieu de O(n)
2. **Recherche dichotomique** : Utilisation de `bisect` pour trouver les timestamps les plus proches
3. **Vectorisation par timestamp** : Groupement des stations par timestamp pour charger les images une seule fois
4. **Cache multi-niveaux** : Les images et ensembles multi-temporels sont mis en cache pour rÃ©utilisation maximale
5. **RÃ©duction I/O** : 95% moins de lectures disque grÃ¢ce au partage d'images entre stations

**Sortie** :

- `datasets/meteonet_SE_2016.h5` (~740 MB par jour)
- Logs de progression et statistiques de construction

**Ce que fait le script** :

1. âœ… Charge les fichiers satellites NetCDF (CT, IR039, IR108, VIS06, WV062) avec **indexation temporelle**
2. âœ… Charge les mesures des stations au sol depuis le CSV avec **prÃ©-indexation (station, timestamp)**
3. âœ… **Groupement intelligent** : Traite les stations par batch de timestamps identiques
4. âœ… Pour chaque timestamp unique :
    - Extrait les **images satellites complÃ¨tes** Ã  t-12h, t-24h, t-48h, t-168h **une seule fois** via **recherche dichotomique O(log n)**
    - RÃ©utilise ces images pour **toutes les stations** du mÃªme timestamp
    - RÃ©cupÃ¨re les mesures au sol (t, hu, precip, dd, ff, psl, td) pour chaque station
    - Aligne temporellement et spatialement les donnÃ©es
5. âœ… Sauvegarde en format HDF5 compressÃ© avec metadata (ou chunks intermÃ©diaires .npz)

**Temps d'exÃ©cution** :

- âš¡ **v2.1 optimisÃ© (mode sÃ©quentiel avec --save-intermediate)** : ~0.5-2 secondes pour 1 jour de donnÃ©es
- ğŸš€ **Performance totale** : 117-1036x plus rapide que la version initiale
- ğŸ“¦ **Mode chunks** : Traite par blocs de 500 samples pour Ã©viter la saturation mÃ©moire
- ğŸ¯ **Exemple rÃ©el** : 4767 samples (1 jour) traitÃ©s en ~14 minutes avec `--save-intermediate`
- âš ï¸ **Sans --save-intermediate** : Beaucoup plus lent car tout est stockÃ© en RAM puis Ã©crit d'un coup
- âš ï¸ **ParallÃ©lisation Windows** : Plus lente que le mode sÃ©quentiel (overhead), non recommandÃ©e

**Optimisations appliquÃ©es** :

| Ã‰tape | Technique | Gain mesurÃ© | Description |
|-------|-----------|-------------|-------------|
| 1ï¸âƒ£ | PrÃ©-indexation temporelle | 8-71x | Recherche dichotomique O(log n) au lieu de O(n) |
| 2ï¸âƒ£ | Vectorisation par timestamp | 14.6x | Groupement des stations, rÃ©duction I/O de 95% |
| ğŸ¯ | **Gain cumulÃ©** | **117-1036x** | Les deux optimisations se multiplient |
| 3ï¸âƒ£ | ParallÃ©lisation (Linux/macOS) | 2-4x | Gain additionnel sur systÃ¨mes Unix uniquement |

ğŸ’¡ **Note** : La parallÃ©lisation n'est pas utile sur Windows en raison de l'overhead du mÃ©canisme `spawn`. Le mode sÃ©quentiel optimisÃ© est dÃ©jÃ  extrÃªmement rapide.

---

### 2ï¸âƒ£ Inspecter le dataset

Le script `tests-louis/inspect_dataset.py` permet de vÃ©rifier la qualitÃ© et la structure du dataset gÃ©nÃ©rÃ©.

```bash
cd tests-louis
python inspect_dataset.py [chemin_dataset.h5]
```

Si aucun chemin n'est fourni, il inspecte automatiquement le dernier dataset crÃ©Ã©.

**Ce qu'il affiche** :

- ğŸ“‹ Structure du fichier HDF5 (dimensions, attributs)
- ğŸ“Š Statistiques sur les images et labels (min, max, mean, NaN%)
- ğŸ“ Info spatiales (stations, coordonnÃ©es)
- â° Info temporelles (pÃ©riode couverte)
- ğŸ” QualitÃ© des donnÃ©es (complÃ©tude par canal et timestep)
- ğŸ¨ Visualisations de samples alÃ©atoires (PNG gÃ©nÃ©rÃ©s)

**Sortie** :

- Statistiques dans le terminal
- `datasets/sample_XXX_visualization.png` (3 samples alÃ©atoires)

---

### 3ï¸âƒ£ Charger le dataset avec PyTorch

Le script `tests-louis/pytorch_dataloader.py` fournit un DataLoader prÃªt Ã  l'emploi pour l'entraÃ®nement.

#### Utilisation simple

```python
from tests-louis.pytorch_dataloader import create_dataloaders
from pathlib import Path

# CrÃ©er les DataLoaders (train/val/test splits automatiques)
train_loader, val_loader, test_loader = create_dataloaders(
    Path("datasets/meteonet_SE_2016_20160101.h5"),
    batch_size=32,
    train_split=0.7,    # 70% train
    val_split=0.15,     # 15% validation
    num_workers=4       # Chargement parallÃ¨le
)

# ItÃ©rer sur les batchs
for images, labels, metadata in train_loader:
    # images: (batch_size, 4_timesteps, 5_channels, height, width)
    # labels: (batch_size, 7_variables)
    # metadata: dict avec timestamp, station_id, coords, etc.

    # â†’ Votre modÃ¨le ici !
    predictions = model(images)
    loss = criterion(predictions, labels)
    # ...
```

#### Utilisation avancÃ©e

```python
from tests-louis.pytorch_dataloader import MeteoNetDataset

# Dataset custom avec options
dataset = MeteoNetDataset(
    h5_path,
    normalize=True,        # Normalisation Z-score par canal
    handle_nans='zero',    # Options: 'zero', 'mean', 'keep'
    transform=None,        # Transformations custom (augmentation)
)

# AccÃ©der aux infos du dataset
print(dataset.get_channel_names())  # ['CT', 'IR039', 'IR108', 'VIS06', 'WV062']
print(dataset.get_target_names())   # ['dd', 'ff', 'precip', 'hu', 'td', 't', 'psl']
print(dataset.get_timesteps())      # [-12, -24, -48, -168]
```

---

### 4ï¸âƒ£ Tester le DataLoader

Script de test rapide pour vÃ©rifier que tout fonctionne.

```bash
cd tests-louis
python test_dataloader.py
```

**Ce qu'il fait** :

- âœ… Charge le dataset
- âœ… CrÃ©e les DataLoaders
- âœ… Teste le chargement d'un batch
- âœ… Affiche les shapes et statistiques

**Sortie attendue** :

```text
âœ… TOUT FONCTIONNE PARFAITEMENT!

ğŸš€ Vous pouvez maintenant:
    1. CrÃ©er un modÃ¨le PyTorch
    2. ItÃ©rer sur train_loader pour l'entraÃ®nement
    3. Ã‰valuer sur val_loader et test_loader
```

---

## ğŸ“Š Format du dataset

### Structure HDF5

```text
dataset.h5
â”œâ”€â”€ images/                    (N, 4, 5, 171, 261)
â”‚   â””â”€â”€ Images satellites :
â”‚       - Dimension 0: Samples
â”‚       - Dimension 1: Timesteps [-12h, -24h, -48h, -168h]
â”‚       - Dimension 2: Canaux [CT, IR039, IR108, VIS06, WV062]
â”‚       - Dimension 3-4: Spatial (171Ã—261 pixels, ~3km/pixel)
â”‚
â”œâ”€â”€ labels/                    (N, 7)
â”‚   â””â”€â”€ Variables mÃ©tÃ©o au sol :
â”‚       [dd, ff, precip, hu, td, t, psl]
â”‚
â””â”€â”€ metadata/
    â”œâ”€â”€ timestamps         Timestamp de chaque sample
    â”œâ”€â”€ station_ids        ID de la station
    â”œâ”€â”€ station_coords     CoordonnÃ©es (lat, lon)
    â”œâ”€â”€ station_heights    Altitude (m)
    â””â”€â”€ zones             Zone gÃ©ographique ('NW' ou 'SE')
```

### Variables

**Canaux satellites** :

- `CT` : Type de nuage (0-15, catÃ©goriel)
- `IR039` : Infrarouge 3.9 Âµm (Â°C)
- `IR108` : Infrarouge 10.8 Âµm (Â°C)
- `VIS06` : Visible 0.6 Âµm (%, jour uniquement)
- `WV062` : Vapeur d'eau 6.2 Âµm (Â°C)

**Labels stations** :

- `dd` : Direction du vent (Â°)
- `ff` : Vitesse du vent (m.s^-1^)
- `precip` : PrÃ©cipitations (kg.m^2^)
- `hu` : HumiditÃ© (%)
- `td` : TempÃ©rature du point de rosÃ©e (K)
- `t` : TempÃ©rature (K)
- `psl` : Pression au niveau de la mer (Pa)

---

## ğŸ”§ Configuration et personnalisation

### Modifier les timesteps

Dans `tests-louis/create_ml_dataset.py` :

```python
class Config:
    TIMESTEPS = [-6, -12, -24, -72]  # 6h, 12h, 1j, 3j au lieu de [-12, -24, -48, -168]
```

### Changer les canaux satellites

```python
class Config:
    CHANNELS = ['IR108', 'VIS06', 'WV062']  # Seulement 3 canaux
```

### SÃ©lectionner certaines variables cibles

```python
class Config:
    TARGET_VARS = ['t', 'hu', 'precip']  # Seulement tempÃ©rature, humiditÃ©, prÃ©cipitations
```

### Ajuster la normalisation

```python
dataset = MeteoNetDataset(
    h5_path,
    normalize=True,      # True = normalisation Z-score
    handle_nans='zero'   # 'zero' | 'mean' | 'keep'
)
```

---

## ğŸ“ˆ Statistiques du dataset (exemple SE_20160101)

### DonnÃ©es gÃ©nÃ©rales

- **Samples** : 2902
- **Stations uniques** : 335
- **Dimensions images** : 171 Ã— 261 pixels
- **Canaux disponibles** : 4 (IR039, IR108, VIS06, WV062) - CT absent pour SE
- **Taux de rÃ©ussite** : 60% (samples avec images ET labels valides)

### QualitÃ© des labels

| Variable | Couverture | Min     | Max      | Mean    |
|----------|-----------|---------|----------|---------|
| t        | 99.9%     | 264 K   | 288 K    | 281 K   |
| hu       | 97.9%     | 44%     | 106%     | 88%     |
| precip   | 96.9%     | 0 kg/mÂ² | 0.8 kg/mÂ²| 0.02    |
| dd       | 93.5%     | 0Â°      | 360Â°     | 138Â°    |
| ff       | 93.5%     | 0 m/s   | 13.7 m/s | 3.4 m/s |
| td       | 97.6%     | 263 K   | 286 K    | 279 K   |
| psl      | 20.0%     | 101190 Pa | 102270 Pa | 101785 Pa |

**Note** : `psl` a peu de couverture (beaucoup de stations ne mesurent pas cette variable).

---

## ğŸ§  Architecture recommandÃ©e pour le ML

### Pourquoi des images complÃ¨tes ?

âœ… **Contexte spatial** : Le modÃ¨le voit les systÃ¨mes mÃ©tÃ©o qui s'approchent  
âœ… **Dynamique temporelle** : Apprend la vitesse/direction des mouvements  
âœ… **GÃ©nÃ©ralisation** : Comprend la relation "mÃ©tÃ©o rÃ©gionale â†’ mÃ©tÃ©o locale"  
âœ… **EfficacitÃ©** : Une image sert pour toutes les stations de la zone

### Timesteps choisis

- **t-12h** : Tendance court terme
- **t-24h** : Ã‰volution sur 1 jour
- **t-48h** : Dynamique Ã  2 jours
- **t-168h** : Contexte hebdomadaire

### Suggestions d'architectures

1. **CNN 3D** : Pour traiter sÃ©quences spatiotemporelles
2. **ConvLSTM** : Combine convolutions + mÃ©moire temporelle
3. **U-Net temporel** : Si vous voulez faire de la prÃ©diction spatiale complÃ¨te
4. **Vision Transformer** : Pour capturer dÃ©pendances long-terme

---

## ğŸ“š Documentation complÃ¨te

Pour plus de dÃ©tails sur la structure HDF5, l'utilisation avancÃ©e, le troubleshooting, etc. :

ğŸ‘‰ **Voir `tests-louis/README_DATASET.md`**

---

## âš ï¸ Points d'attention

### Valeurs manquantes (NaN)

- **VIS06** : Pas de donnÃ©es la nuit (normal)
- **CT** : Peut Ãªtre absent selon la zone
- **Labels** : `psl` souvent absent (80% de NaN)

**Recommandation** : Utiliser `handle_nans='zero'` dans le DataLoader.

### Performance

- **Dataset complet** : ~740 MB pour 1 jour â†’ ~270 GB pour 1 an
- **Solution** : HDF5 permet le chargement lazy (pas tout en RAM)
- **Optimisation** : Augmenter `num_workers` dans le DataLoader

### Gestion mÃ©moire

```python
# Pour gros datasets, rÃ©duire batch_size ou utiliser gradient accumulation
train_loader = DataLoader(dataset, batch_size=16)  # Au lieu de 32
```

---

## ğŸš€ Prochaines Ã©tapes

### Pour commencer l'entraÃ®nement

1. **CrÃ©er un modÃ¨le simple** pour tester le pipeline
2. **DÃ©finir la loss function** (MSE, MAE, ou custom ignorant les NaN)
3. **EntraÃ®ner** sur quelques epochs
4. **Ã‰valuer** les performances sur val/test

### Pour Ã©tendre le dataset

1. **Dataset complet** : GÃ©nÃ©rer pour toute l'annÃ©e 2016
2. **Multi-zones** : Combiner NW et SE
3. **Autres sources** : Ajouter donnÃ©es radar, AROME/ARPEGE
4. **Multi-annÃ©es** : 2016, 2017, 2018...

---

## ğŸ› Troubleshooting

### Erreur "No module named 'h5py'"

```bash
pip install h5py
```

### Erreur "Indexing elements must be in increasing order"

HDF5 nÃ©cessite des indices triÃ©s :

```python
indices = np.sort(indices)
```

### Performances lentes

- Augmenter `num_workers` dans DataLoader
- VÃ©rifier que le HDF5 est sur un SSD
- RÃ©duire `batch_size` si RAM insuffisante

### Dataset trop gros

- RÃ©duire la pÃ©riode (1 semaine au lieu de 1 mois)
- Sous-Ã©chantillonner temporellement (1 sample toutes les 3h)
- Utiliser moins de canaux satellites

---

## ğŸ“ Contact et contribution

Projet dÃ©veloppÃ© dans le cadre du TIP - INSA Lyon 4TCA.

**Sources de donnÃ©es** : [MeteoNet](https://meteonet.umr-cnrm.fr/) - MÃ©tÃ©o-France

---

## ğŸ“„ Licence

Voir `LICENCE.md` pour les dÃ©tails.

---

Bon entraÃ®nement ! ğŸŒ¦ï¸ğŸš€
